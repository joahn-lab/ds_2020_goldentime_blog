---
title: "응급의료 취약지 분석"
author: "[Golden Time](https://github.com/twg12/IntroToDataScience_5)"
date: "`r Sys.Date()`"
output:
  html_document: 
    toc: yes
    toc_float: true
    highlight: tango
    code_folding: show
    number_section: true
    self_contained: true
editor_options: 
  chunk_output_type: console
slug: final_report
categories: []
tags: []
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE, result='hide', message=FALSE}
mylocation = "C:\\Users\\YoonHoJeong\\Desktop\\Projects\\data_science_2020\\viz\\final_blog"

setwd(mylocation)

library(knitr)
library(readr)
library(tidyverse)
library(skimr)
library(stringr)
library(recipes)
library(tidymodels)

library(httr)
library(XML)
library(xml2)
library(writexl)
library(tictoc)
```

# 프로젝트 소개
## 주제
접근성과 의료 시설 인프라 분석을 통한 종합적 응급 의료 취약지 선정.

## 기존 응급 의료 취약지 선정의 문제점

- ["보건복지부는 최근 행정예고를 통해 ‘**지역응급의료센터로 30분내 도달이 불가능**하거나, **권역응급의료센터로 1시간 이내 도달이 불가능**한 인구가 지역 내 30% 이상인 지역’을 응급의료취약지로 지정하도록 했다."](http://www.docdocdoc.co.kr/news/articleView.html?idxno=1038322)
- '**접근성**'만을 기준으로 삼는다.

이를 통해 선정한 응급 의료 취약지 선정은 아래와 같은 이유로 현 응급 의료 실태와 일치하지 않는 경우가 발생한다.

1. **응급의료기관의 인프라(시설)이 고려되지 않는다.**
"동맥박리, 사지절단 환자를 수술할 수 있는 의사는 국내 10여명뿐인데 해외출장 중이라면 다른 병원 의사를 물색해야 하고, 독극물 중독 환자에게는 해독제를 줘야 하는데, 해독제가 있는 병원도 전국에 20여곳뿐"
    - 해당 병원이 얼마나 많은 환자를 수용할 수 있으며, 어떤 응급 처치를 수행할 수 있는지에 대한 분석이 제외되어있다.
    - 이는, 해당 자원이 부족한 응급 시설에 대한 지원 부족으로 이어질 수 있으며, 아래와 같은 문제점을 유발한다.  
  
2. **다른 병원 재이송**
    - 병원이 응급 진료를 거부하는 주요 이유로는,  1) 전문의 부재(23.2%), 2) 진료과 없음(13.4%) 두가지가 1, 2위를 차지
    - 추가적으로, 병상부족이 8.6%를 차지
    - 한 해 약 1050만명의 환자가 응급실을 찾지만, 다른 병원으로 재이송 되는 사례는 약 3만 3000여건이다. 이 중 전문의 부재, 진료과 없음의 이유로 재이송 되는 비율은 36.6%를 차지한다. 
    - '병상 부족'이라는 사유를 포함하면 약 1만 5000여건의 응급 상황이 의료 시설 인프라를 이유로 골든 타임을 놓치게 된다.

## 프로젝트 목차

위와 같은 현재 응급 의료 취약지 선정의 한계점으로부터, 우리는 골든타임의 측정은 단순한 인근 의료시설의 접근 시간에 대한 지수가 되어서는 안되며, 적절한 응급 인프라를 통해 정확한 진료를 받을 수 있을 때까지의 시간으로 측정되어야 한다는 점에 동의했다.
  
프로젝트는 아래와 같이 진행된다.
  
1. **접근성 분석**  
특정 좌표를 중심으로 제한된 반경 내에 존재하는 병원의 수를 측정한다.  

1. **응급 의료 시설의 인프라 점수 분석**  
병원의 재이송 비율을 병상수와 같은 응급 환자 수용 시설과 관련된 요인에서부터, 심혈관 전문의 등, 해당 병원의 특정 질환을 갖는 응급 환자 수용 가능 여부에 대한 변수를 설정하고 이에 대한 점수를 통계적 기법을 통해 제시한다.  

1. **종합적 응급 의료 취약지 도출**  
인구 밀도, 앞서 분석한 접근성, 인프라 점수를 종합적으로 분석해 응급의료 취약지를 도출한다.  

1. **추후 제언**  
제언을 위한 응급의료기관 입지 선정의 최소비용 최대효율을 낼 수 있는 장소를 예측한다.

# 데이터 선정

1. [공공데이터포털 - 전국 응급의료기관 조회 서비스](https://www.data.go.kr/data/15000563/openapi.do)  
응급 의료 기관의 좌표, 인프라에 필요한 정보를 얻을 수 있었다.

2. [전국 행정구역 지역 좌표](http://www.gisdeveloper.co.kr/?p=2332)  
특정 지역의 기준을 설정할 행정 구역별 좌표를 불러온다.  
해당 데이터는 폴리곤 좌표로, 이를 경, 위도 좌표로 변환해 사용했다.

# 데이터 수집
## 응급의료기관 기본 정보 조회 서비스

```{r eval=FALSE, result='hide', message=FALSE}

# 응급의료기관 기본정보 조회 서비스
url = "http://openapi2.e-gen.or.kr/openapi/service/rest/ErmctInfoInqireService/"


## 응급실 실시간 가용병상정보 조회 1번 오퍼레이터
  
operator = "getEmrrmRltmUsefulSckbdInfoInqire"
Servicekey = "your_service_key"
pageNo = "1"
numOfRows = "99"
  
result_table_1 = tibble()
for (i in 1:10){
  queryParams = str_c("?serviceKey=", Servicekey, "&pageNo=", as.character(i), "&numOfRows=", "50")
  doc = xmlInternalTreeParse(str_c(url, operator, queryParams))
  rootNode = xmlRoot(doc)
  names = rootNode[[2]][['items']][['item']] %>%
    names()
  tmp_tbl = xmlToDataFrame(nodes = getNodeSet(rootNode, '//item')) %>%
    set_names(iconv(names, "UTF-8", "CP949") %>% unname()) %>%
    as_tibble()
  result_table_1 = result_table_1 %>% bind_rows(.,tmp_tbl)
}
  
which(result_table_1$dutyName == "의료법인명지의료재단명지병원")
result_table_1[c(23, 391),] # 이름은 같지만 지역이 다른 명지병원이므로 인정
  # 응급의료기관 지정 병원 갯수가 대략 402개 나옵니다
  
write_xlsx(result_table_1, "응급의료기관 기본정보 조회 서비스_1.xlsx")
write_excel_csv(result_table_1, "result_0527_12_16.csv")

```


## 응급의료기관 목록정보 조회
```{r, eval=FALSE}
## 응급의료기관 조회서비스 3번 오퍼레이터 - 좌표값 찾기


pageNo = "1"
numOfRows = "99" # "&pageNo=", pageNo, "&numOfRows=", numOfRows
operator = "getEgytListInfoInqire"
  
result_table_3 = tibble()
  
for (i in 1:402){
  QN = result_table_1[i,1]
  queryParams = str_c("?serviceKey=", Servicekey, "&QN=", QN)
  doc = xmlInternalTreeParse(str_c(url, operator, queryParams))
  rootNode = xmlRoot(doc)
  tmp_tbl_2 = xmlToDataFrame(nodes = getNodeSet(rootNode, '//items//hpid')) %>% as_tibble(.name_repair = "unique")
  tmp_tbl_3 = xmlToDataFrame(nodes = getNodeSet(rootNode, '//items//dutyName')) %>% as_tibble(.name_repair = "unique")
  tmp_tbl_4 = xmlToDataFrame(nodes = getNodeSet(rootNode, '//items//wgs84Lon')) %>% as_tibble(.name_repair = "unique")
  tmp_tbl_5 = xmlToDataFrame(nodes = getNodeSet(rootNode, '//items//wgs84Lat')) %>% as_tibble(.name_repair = "unique")
  tmp_tbl_2 = tmp_tbl_2 %>% bind_cols(.,tmp_tbl_3) %>% bind_cols(.,tmp_tbl_4) %>% bind_cols(.,tmp_tbl_5)
  result_table_3 = result_table_3 %>% bind_rows(.,tmp_tbl_2)}
  

write_xlsx(result_table_3, "응급의료기관 목록정보 조회 서비스_3.xlsx")



```

## 중증질환자 수용가능 정보 오퍼레이터
```{r eval=FALSE, error= FALSE, message=FALSE}
# (2) 중증질환자 수용가능 정보 오퍼레이터

operator = "getSrsillDissAceptncPosblInfoInqire"
result_table_2 = tibble()
  
for (i in 1:40){
  queryParams = str_c("?serviceKey=", Servicekey, "&pageNo=", as.character(i), "&numOfRows=", "14")
  doc = xmlInternalTreeParse(str_c(url, operator, queryParams))
  rootNode = xmlRoot(doc)
  names = rootNode[[2]][['items']][['item']] %>%
    names()
  tmp_tbl_2 = xmlToDataFrame(nodes = getNodeSet(rootNode, '//items')) %>%
    as_tibble(.name_repair = "unique")
  result_table_2 = result_table_2 %>% bind_rows(.,tmp_tbl_2)}
  
result_table_2.df = tibble()
for (i in 1:23){
  for (j in 1:14){
    result_table_2.df[j+14*(i-1),1] = str_extract(result_table_2[i,j], "[가-힣]+")
    result_table_2.df[j+14*(i-1),2] = str_extract(result_table_2[i,j], "[a-zA-Z][0-9]+")
    result_table_2.df[j+14*(i-1),3] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 1, 1)
    result_table_2.df[j+14*(i-1),4] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 2, 2)
    result_table_2.df[j+14*(i-1),5] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 3, 3)
    result_table_2.df[j+14*(i-1),6] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 4, 4)
    result_table_2.df[j+14*(i-1),7] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 5, 5)
    result_table_2.df[j+14*(i-1),8] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 6, 6)
    result_table_2.df[j+14*(i-1),9] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 7, 7)
    result_table_2.df[j+14*(i-1),10] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 8, 8)
    result_table_2.df[j+14*(i-1),11] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 9, 9)
    result_table_2.df[j+14*(i-1),12] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 10, 10)
    result_table_2.df[j+14*(i-1),13] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 11, 11)
    result_table_2.df[j+14*(i-1),14] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 12, 12)}}
result_table_2.df = result_table_2.df[1:313,]
  
write_xlsx(result_table_2.df, "중증질환자 수용가능 정보_2.xlsx")

```

## 응급의료기관 기본정보 조회 오퍼레이션
```{r eval=FALSE, error=FALSE, message=FALSE}
## (5) 응급의료기관 기본정보 조회 오퍼레이션

operator = "getEgytBassInfoInqire"
result_table_5 = tibble()
  
for (i in 1:2000){
  tic()
  queryParams = str_c("?serviceKey=", Servicekey, "&pageNo=", as.character(i), "&numOfRows=", "50")
  doc = xmlInternalTreeParse(str_c(url, operator, queryParams))
  rootNode = xmlRoot(doc)
  tmp_tbl_2 = xmlToDataFrame(getNodeSet(rootNode, "//item")) %>% as_tibble()
  result_table_5 = result_table_5 %>% bind_rows(.,tmp_tbl_2)
  toc()
}
write_xlsx(result_table_5, "응급의료기관 기본정보 조회_5_1.xlsx")
  
table(duplicated(result_table_5$dutyName))
}
```

## 외상센터 기본정보 조회 오퍼레이션
```{r eval=FALSE, error=FALSE, message=FALSE}
## (8) 외상센터 기본정보 조회 오퍼레이션

api_call_func5 <- function() {
  operator = "getStrmBassInfoInqire"
  result_table_8 = tibble()
  for (i in 1:10){
    queryParams = str_c("?serviceKey=", Servicekey, "&pageNo=", as.character(i), "&numOfRows=", "50")
    doc = xmlInternalTreeParse(str_c(url, operator, queryParams))
    rootNode = xmlRoot(doc)
    tmp_tbl_3 = xmlToDataFrame(nodes = getNodeSet(rootNode, '//item')) %>% as_tibble()
    result_table_8 = result_table_8 %>% bind_rows(.,tmp_tbl_3)}
  
  write_xlsx(result_table_8, "외상센터 기본정보 조회_8.xlsx")
}
```

# 접근성 분석
- 대한민국 지도에서 읍, 면, 동 단위로 각 지점에서 특정 거리 내에 있는 응급 의료 시설 거리를 합산한다. 그 중 30분 내에 도달 가능한 병원이 없는 경우 취약지역으로 선정한다. 정부는 ‘공공보건의료에 관한 법률’ 제12조 제2항 및 제3항에 의해서 응급의료분야 의료취약지를 선정하고 있는데, 구체적인 기준은 다음과 같다.
  
**지역내 30% 이상의 인구가 지역응급의료센터로 30분 이내 도달이 불가능하거나 권역응급의료센터로 1시간 이내 도달이 불가능한 경우**
  
따라서 30분 이내 도달 가능한 병원이 없는 지역을 일차적으로 응급의료취약지역으로 설정하고 시각화에 반영한다. 세부 사항은 추후 classification 과정에서 감안할 것이다.

# 의료시설 인프라 점수 도출
* **_목적_** : 병원이 제공하는 응급의료 서비스의 지표로 활용할 수 있는 병원 점수를 만든다.

* **_데이터의 특성_** : 공공데이터에서 구할 수 있는 자료는 우리나라 병원 전체에 대한 자료이기 때문에 예측이나 추정 모델이 필요하지 않다.

* **_분석방법_** : 주성분분석(PCA)을 통해 우리나라 병원 데이터의 특성을 반영한 응급의료점수를 구한다.

```{r include=FALSE}
library(readr)
library(tidyverse)
library(skimr)
library(stringr)
library(recipes)
library(tidymodels)
```


## 탐색적 자료 분석 EDA
### API를 통해 저장한 csv파일 불러오기
2개의 파일은 다음과 같다.

1. '응급의료기관 기본정보 조회 서비스_1.csv'
2. '중증질환자 수용가능 정보_2.csv'

```{r read-data, include=FALSE}
table_1 <- read_csv('응급의료기관 기본정보 조회 서비스_1.csv')
table_2 <- read_csv('중증질환자 수용가능 정보_2.csv')
```

### 표 합치기
dplyr 패키지의 inner_join함수를 통해 불러온 두개의 표를 합친다. 합칠 때 기준이 되는 것은 병원의 ID('hpid')이다.

```{r}
hpdata <- inner_join(table_1, table_2, by='hpid')
```

### 변수선택
응급의료에 영향을 주는 변수를 선택했다. 선택에서 제외된 변수는 '응급실 당직 직통연락처', '외과입원실', '신결과입원실',
'약물중환자', '화상중환자', '외상중환자', '소아당직 직통연락처', '입력일시', '신경중환자', '일반중환자', '신생중환자', '흉부중환자', '정신질환자 수용가능여부', '응급실 지킴이 유무'이다.
```{r}
hpdata <- hpdata %>%
  select(dutyName.x, starts_with('h'), starts_with('mk'))%>%
  select(-hv1, -hv4, -hv5, -hv7, -hv8, -hv9, -hv12, -hvidate, -hvcc, -hvncc, -hvccc, -hvicc, -mkioskty25, -mkioskty9)
#glimpse(hpdata)
#str(hpdata)
```
### 변수 별로 변수가 취하는 값의 개수
변수가 취할 수 있는 값의 개수를 확인하여 변수의 특성을 확인하였다.
```{r}
nuniq <- c()
for(i in 1:length(colnames(hpdata))) {
  nuniq[i] <- hpdata[,i] %>%
  n_distinct()
}
nuniq
```
### 분산이 0인 변수를 제거
```{r}
hpdata <- hpdata[,nuniq!=1]
```
```{r}
#str(hpdata)
nuniq <- c()
for(i in 1:length(colnames(hpdata))) {
  nuniq[i] <- hpdata[,i] %>%
  n_distinct()
}
nuniq
```
### 0과 1, 또는 Yes와 No로 나뉘는 가변수들을 따로 분리한다.
```{r}
hpdata_f <- hpdata[,nuniq<=3]
hpdata_n <- hpdata[,nuniq>3]
```
### 가변수들이 0과 1로 통일되도록 하고 분리했던 변수들을 다시 합친다. 
```{r}
hpdata_f <- hpdata_f %>%
  mutate_all(funs(recode(., 'N1'=0L, '0'=0L, 'N'=0L, '1'=1L, 'Y'=1L, .default=1L)))
#str(hpdata_f)
```
```{r}
hpdata <- bind_cols(hpdata_n, hpdata_f)
#glimpse(hpdata)
```
### 각변수를 평균=0, 분산=1로 정규화 한다. 
```{r}
hpdata_z <- hpdata %>%
  mutate_each_(funs(scale), vars=colnames(hpdata)[3:length(colnames(hpdata))])
write.csv(hpdata_z, file="scaled_data.csv", row.names = FALSE)
```
### 공선성 진단
```{r}
multi <- lm(1:nrow(hpdata_z)~hv2+hv3+hv6+hvec+hvgc+hvoc+hv10+hv11+hvctayn+hvmriayn+hvventiayn+mkioskty1+mkioskty2+mkioskty3+mkioskty4+ mkioskty5+mkioskty6+mkioskty7+mkioskty8+mkioskty10+mkioskty11, data = hpdata_z, na.action = na.omit)
#alias(multi)
car::vif(multi)
```
공선성이 진단되지 않았기 때문에 주성분분석을 통해 구성된 점수를 해석하는 것이 가능하다.

******

## 주성분 분석

### 주성분 분석
```{r}
hp_without_id <- hpdata_z[,3:length(colnames(hpdata_z))] %>%
    as.matrix()
hp_pca <- prcomp(hp_without_id)
hp_pca[[1]] # 각 축들의 표준편차
```
```{r}
hp_pca[[2]][,1:3] # 1~3번째 축에서 나타나는 변수별 가중치
```
첫번째 축을 보면 모든 변수들의 가중치가 같은 방향으로 부여되는 것을 확인할 수 있다. 
\[y=\beta_1X_1+\beta_2X_2+\beta_3X_3+ ... \beta_{21}X_{21}\]이고, 각 \(\beta\)들은 음의 값으로 나왔기 때문에, -y에 적절한 상수를 곱하고 더하여 병원 점수를 구성할 수 있다. 

### 설명된 분산의 양: \(R^2\)
첫번째 축은 전체 분산의 28.9%를 설명한다. 그 다음 축들이 설명하는 분산의 양은 10.2%, 6.3%, ... 로 첫번째 축에 비해 급격하게 줄어드는 모습을 볼 수 있다. 
```{r}
summary(hp_pca)
```
설명된 분산의 양을 scree plot을 통해 나타내면 다음과 같다.
```{r}
screeplot(hp_pca, col = "blue", type = "lines", pch = 21, main="Scree Plot")
```


### 첫번째 축을 활용하여 병원 점수 구성하기
##### 점수의 평균은 100, 표준편차는 20이다.
```{r}
hp_pc1 <- predict(hp_pca)[,1] # 첫번째 축에 각 데이터를 정사영하여 병원점수를 구성한다.
hp_score <- (100-20*scale(hp_pc1))
hospital_score <- hpdata %>%
  select(dutyName.x,hpid)%>%
  mutate(score=hp_score)     # 병원이름, 병원ID, 병원점수를 선택하여 'hospital_score'라는 표를 만든다. 
skim(hospital_score)
```


### 병원점수 시각화
```{r}
library(ggplot2)
ggplot(hospital_score, aes(x=score))+
  geom_histogram(fill='sky blue', binwidth = 3)
```

### 병원점수 .csv 파일로 내보내기
```{r}
write.csv(hospital_score, file = 'hospital_score', row.names = FALSE)
```
```{r}
hp_score[hp_score > 112.5] %>% #상위 점수의 평균
  mean()
hp_score[hp_score < 112.5] %>% #하위 점수의 평균
  mean()
```

******

## 입력 변수에 따라 점수 만들기 

### 소개

* 변수 입력에 따라 병원점수를 만들어주는 함수를 만들었다.

### 입력값

* c("응급실", "hv2")와 같이 문자벡터를 입력해야 한다. 한글명과 영문명 모두 입력 가능하다. 

### 함수 종류

* LetsMakeScore_Score - dplyr 패키지의 skim 함수를 통해 점수를 요약해준다.

* LetsMakeScore_Plot - histogram을 그려준다.

* LetsMakeScore_CSV - .csv 파일로 점수를 내보낸다. csv파일에서는 병원 이름과 병원 ID를 함께 확인할 수 있다.

### 사용할 수 있는 변수
*한글명*        |   *영어명*
----------------|--------------
내과중환자실    |   hv2
외과중환자실    |   hv3
신경외과중환자실|   hv6
응급실          |   hvec
입원실          |   hvgc 
수술실          |   hvoc 
소아            |   hv10
인큐베이터      |   hv11
CT              |   hvctayn
MRI             |   hvmriayn
인공호흡기      |   hvventiayn 
뇌출혈수술      |   mkioskty1
뇌경색수술      |   mkioskty2
심근경색수술    |   mkioskty3
복부손상수술    |   mkioskty4
사지접합수술    |   mkioskty5
응급내시경      |   mkioskty6
응급투석        |   mkioskty7
조산산모        |   mkioskty8
신생아          |   mkioskty10 
중증화상        |   mkioskty11

### 함수 사용 예시
```{r Code, include=FALSE}
##한글 입력 값을 영어로 바꿔주기#############
 I <- function(x) {
  Input <- c(x) %>%
    recode("내과중환자실"="hv2", 
"외과중환자실"="hv3", 
"신경외과중환자실"="hv6",
"응급실"="hvec",
"입원실"="hvgc", 
"수술실"="hvoc", 
"소아"="hv10",
"인큐베이터"="hv11", 
"CT"="hvctayn",
"MRI"="hvmriayn",
"인공호흡기"="hvventiayn", 
"뇌출혈수술"="mkioskty1",
"뇌경색수술"="mkioskty2",
"심근경색수술"="mkioskty3",
"복부손상수술"="mkioskty4",
"사지접합수술"="mkioskty5",
"응급내시경"="mkioskty6",
"응급투석"="mkioskty7",
"조산산모"="mkioskty8" ,
"신생아"="mkioskty10", 
"중증화상"="mkioskty11")
  return(Input)
 }
##그림 그리기############################
LetsMakeScore_Plot <- function(x) {
hpdata_z <- read.csv("scaled_data.csv")
  sc <- hpdata_z %>%
  select(I(x))%>%
  prcomp()
sc_2 <- predict(sc)[,1]
ifelse(sum(sc[[2]][,1]) > 0, sc <- sc_2, sc <- -sc_2)  
sc <- 100+20*scale(sc)
sc <- ifelse(sc<0, 0, sc)
hp_score <- hpdata_z %>%
  select(dutyName.x, hpid) %>%
  mutate(score= sc)
hp_score %>%
  ggplot(aes(x=score)) +
  geom_histogram(fill='sky blue', binwidth = 3)
}
##skim 함수를 통한 점수분포###############
LetsMakeScore_Score <- function(x) {
hpdata_z <- read.csv("scaled_data.csv")
  sc <- hpdata_z %>%
  select(I(x))%>%
  prcomp()
sc_2 <- predict(sc)[,1]
ifelse(sum(sc[[2]][,1]) > 0, sc <- sc_2, sc <- -sc_2)  
sc <- 100+20*scale(sc)
sc <- ifelse(sc<0, 0, sc)
hp_score <- hpdata_z %>%
  select(dutyName.x, hpid) %>%
  mutate(score= sc)
hp_score %>%
  select(score)%>%
  skim()
}
##.csv 파일로 내보니기#########################################
LetsMakeScore_CSV <- function(x) {
hpdata_z <- read.csv("scaled_data.csv")
  sc <- hpdata_z %>%
  select(I(x))%>%
  prcomp()
sc_2 <- predict(sc)[,1]
ifelse(sum(sc[[2]][,1]) > 0, sc <- sc_2, sc <- -sc_2)  
sc <- 100+20*scale(sc)
sc <- ifelse(sc<0, 0, sc)
hp_score <- hpdata_z %>%
  select(dutyName.x, hpid) %>%
  mutate(score= sc)
write.csv(hp_score, file = "EmergenHP_Score_User_Custom.csv", row.names = FALSE)
}
```

```{r}
LetsMakeScore_Plot(c("응급실","입원실","수술실"))
#LetsMakeScore_Plot(c("CT","MRI","응급실", "수술실"))
```
```{r}
LetsMakeScore_Score(c("응급실","입원실","수술실"))
#LetsMakeScore_Score(c("CT","MRI","응급실", "수술실"))
```
```{r}
LetsMakeScore_CSV(c("응급실","입원실","수술실"))
#LetsMakeScore_CSV(c("CT","MRI","응급실", "수술실"))
```




```{r, eval=FALSE, include=FALSE}
# 인구 밀도에 따른 국내 지도 시각화

library(sp)
library(rgdal)

TL = readOGR(mylocation, "LI") # 첫 인자에 파일 위치, 두번째 인자에 파일명

# Option1 불러온 공간 데이터 내에서 좌표계 방식 변환  (UTM-K -> WGS84)

# from.crs = TL@proj4string
to_crs = CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
TL_1 = spTransform(TL, to_crs)

tmp_1 = TL_1@data

for (i in 1:nrow(tmp_1)){
  tmp_1$x_coord[i] = parse_number(as.character(TL_1@polygons[[i]]@labpt)[1])
  tmp_1$y_coord[i] = parse_number(as.character(TL_1@polygons[[i]]@labpt)[2])
}

# Haversine 공식으로 거리 계산

library(geosphere)

dist = list()
for (i in 1:nrow(tmp_1)){
dist[[i]] = c(tmp_1$x_coord[i], tmp_1$y_coord[i])
}

medi = list()
for (i in 1:nrow(result_table_3)){
  medi[[i]] = c(parse_number(result_table_3$text2[i]), parse_number(result_table_3$text3[i]))
}

# 거리 계산하여 10km 이내에 도달 가능한 응급의료기관 수 계산

tmp_1$num = 0
for (i in 1:length(dist)){
  for (j in 1:length(medi)){
  ifelse(distHaversine(dist[[i]], medi[[j]])<10000, tmp_1$num[i] <- tmp_1$num[i]+1, next)
  }
}
```

```{r, eval=FALSE, include=FALSE}
write.csv(tmp_1, "Haversine_list.csv")
```

```{r, eval=FALSE, include=FALSE}
library(leaflet)

TL_1 = sp::merge(TL_1, tmp_1)

# Shiny Dashboard 활용

library(shiny)
library(shinydashboard)

ui <- fluidPage(
  mainPanel( 
leafletOutput(outputId = "mymap")))

server <- function(input, output, session) {
  pal2 = colorNumeric("viridis", TL_1@data$num, reverse=TRUE)
  
  output$mymap = renderLeaflet({leaflet(TL_1) %>%
    setView(lng=127.7669,lat=35.90776, zoom=7) %>%
    addProviderTiles('CartoDB.Positron') %>%
    addPolygons(color='#444444', weight=0.5, opacity = 1.0, fillOpacity = 0.5, fillColor=~pal2(num))
  })
}

shinyApp(ui, server)
```
